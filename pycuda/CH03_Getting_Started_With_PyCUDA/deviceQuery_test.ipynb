{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device query (PyCUDA version) \n",
      "\n",
      "Detected 1 CUDA Capable device(s) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pycuda\n",
    "import pycuda.driver as drv\n",
    "drv.init()\n",
    "\n",
    "print 'CUDA device query (PyCUDA version) \\n'\n",
    "\n",
    "print 'Detected {} CUDA Capable device(s) \\n'.format(drv.Device.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: Tesla K80\n",
      "\t Compute Capability: 3.7\n",
      "\t Total Memory: 11439 megabytes\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "gpu_device = drv.Device(i)\n",
    "print 'Device {}: {}'.format( i, gpu_device.name() ) \n",
    "compute_capability = float( '%d.%d' % gpu_device.compute_capability() )\n",
    "print '\\t Compute Capability: {}'.format(compute_capability)\n",
    "print '\\t Total Memory: {} megabytes'.format(gpu_device.total_memory()//(1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_attributes_tuples = gpu_device.get_attributes().iteritems() \n",
    "device_attributes = {}\n",
    "    \n",
    "for k, v in device_attributes_tuples:\n",
    "        device_attributes[str(k)] = v\n",
    "    \n",
    "num_mp = device_attributes['MULTIPROCESSOR_COUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t (13) Multiprocessors, (32) CUDA Cores / Multiprocessor: 416 CUDA Cores\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cores per multiprocessor is not reported by the GPU!  \n",
    "# We must use a lookup table based on compute capability.\n",
    "# See the following:\n",
    "# http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities\n",
    "    \n",
    "cuda_cores_per_mp = {3.7:32, 5.0 : 128, 5.1 : 128, 5.2 : 128, 6.0 : 64, 6.1 : 128, 6.2 : 128}[compute_capability]\n",
    "    \n",
    "print '\\t ({}) Multiprocessors, ({}) CUDA Cores / Multiprocessor: {} CUDA Cores'.format(num_mp, cuda_cores_per_mp, num_mp*cuda_cores_per_mp)\n",
    "    \n",
    "device_attributes.pop('MULTIPROCESSOR_COUNT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: Tesla K80\n",
      "\t Compute Capability: 3.7\n",
      "\t Total Memory: 11439 megabytes\n",
      "\t (13) Multiprocessors, (32) CUDA Cores / Multiprocessor: 416 CUDA Cores\n",
      "\t MAXIMUM_TEXTURE2D_LINEAR_PITCH: 1048544\n",
      "\t MAXIMUM_TEXTURE2D_GATHER_WIDTH: 16384\n",
      "\t MAXIMUM_TEXTURE2D_GATHER_HEIGHT: 16384\n",
      "\t PCI_DEVICE_ID: 30\n",
      "\t MAXIMUM_TEXTURE3D_WIDTH: 4096\n",
      "\t MAXIMUM_SURFACE2D_WIDTH: 65536\n",
      "\t MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH: 16384\n",
      "\t GLOBAL_MEMORY_BUS_WIDTH: 384\n",
      "\t LOCAL_L1_CACHE_SUPPORTED: 1\n",
      "\t MAXIMUM_SURFACE3D_DEPTH: 2048\n",
      "\t MAXIMUM_TEXTURE3D_HEIGHT: 4096\n",
      "\t PCI_DOMAIN_ID: 0\n",
      "\t COMPUTE_CAPABILITY_MINOR: 7\n",
      "\t MULTI_GPU_BOARD_GROUP_ID: 0\n",
      "\t MAX_REGISTERS_PER_BLOCK: 65536\n",
      "\t MAXIMUM_TEXTURE2D_ARRAY_WIDTH: 16384\n",
      "\t COMPUTE_CAPABILITY_MAJOR: 3\n",
      "\t MAXIMUM_SURFACE2D_LAYERED_HEIGHT: 32768\n",
      "\t MAXIMUM_TEXTURE1D_LAYERED_LAYERS: 2048\n",
      "\t UNIFIED_ADDRESSING: 1\n",
      "\t MAXIMUM_TEXTURE1D_LINEAR_WIDTH: 134217728\n",
      "\t MAXIMUM_SURFACE3D_WIDTH: 65536\n",
      "\t MAXIMUM_SURFACE2D_HEIGHT: 32768\n",
      "\t ECC_ENABLED: 1\n",
      "\t MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES: 2048\n",
      "\t MAX_GRID_DIM_Y: 65535\n",
      "\t MAX_GRID_DIM_X: 2147483647\n",
      "\t MAX_GRID_DIM_Z: 65535\n",
      "\t SURFACE_ALIGNMENT: 512\n",
      "\t MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE: 16384\n",
      "\t MAXIMUM_SURFACE1D_LAYERED_LAYERS: 2048\n",
      "\t TOTAL_CONSTANT_MEMORY: 65536\n",
      "\t MAXIMUM_SURFACE1D_LAYERED_WIDTH: 65536\n",
      "\t MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS: 2046\n",
      "\t MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE: 2048\n",
      "\t MAXIMUM_SURFACE2D_LAYERED_LAYERS: 2048\n",
      "\t MAXIMUM_TEXTURECUBEMAP_WIDTH: 16384\n",
      "\t GPU_OVERLAP: 1\n",
      "\t MAXIMUM_TEXTURE3D_DEPTH: 4096\n",
      "\t CAN_MAP_HOST_MEMORY: 1\n",
      "\t INTEGRATED: 0\n",
      "\t MAXIMUM_SURFACE1D_WIDTH: 65536\n",
      "\t MAX_THREADS_PER_MULTIPROCESSOR: 2048\n",
      "\t MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT: 16384\n",
      "\t STREAM_PRIORITIES_SUPPORTED: 1\n",
      "\t MAXIMUM_SURFACECUBEMAP_WIDTH: 32768\n",
      "\t MAXIMUM_TEXTURE1D_LAYERED_WIDTH: 16384\n",
      "\t PCI_BUS_ID: 0\n",
      "\t GLOBAL_L1_CACHE_SUPPORTED: 1\n",
      "\t TEXTURE_ALIGNMENT: 512\n",
      "\t ASYNC_ENGINE_COUNT: 2\n",
      "\t MAX_PITCH: 2147483647\n",
      "\t MAXIMUM_SURFACE2D_LAYERED_WIDTH: 65536\n",
      "\t CLOCK_RATE: 823500\n",
      "\t MAXIMUM_TEXTURE2D_HEIGHT: 65536\n",
      "\t MAXIMUM_SURFACE3D_HEIGHT: 32768\n",
      "\t MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH: 16384\n",
      "\t TEXTURE_PITCH_ALIGNMENT: 32\n",
      "\t MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE: 2048\n",
      "\t MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH: 32768\n",
      "\t MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH: 16384\n",
      "\t MAXIMUM_TEXTURE2D_LINEAR_WIDTH: 65000\n",
      "\t TCC_DRIVER: 0\n",
      "\t MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS: 2046\n",
      "\t WARP_SIZE: 32\n",
      "\t CONCURRENT_KERNELS: 1\n",
      "\t MAX_BLOCK_DIM_Z: 64\n",
      "\t MAXIMUM_TEXTURE2D_ARRAY_HEIGHT: 16384\n",
      "\t MAX_THREADS_PER_BLOCK: 1024\n",
      "\t L2_CACHE_SIZE: 1572864\n",
      "\t MAXIMUM_TEXTURE2D_LINEAR_HEIGHT: 65000\n",
      "\t KERNEL_EXEC_TIMEOUT: 0\n",
      "\t COMPUTE_MODE: DEFAULT\n",
      "\t MANAGED_MEMORY: 1\n",
      "\t MULTI_GPU_BOARD: 1\n",
      "\t MAXIMUM_TEXTURE2D_WIDTH: 65536\n",
      "\t MAX_SHARED_MEMORY_PER_BLOCK: 49152\n",
      "\t MAX_BLOCK_DIM_Y: 1024\n",
      "\t MAX_BLOCK_DIM_X: 1024\n",
      "\t MAX_SHARED_MEMORY_PER_MULTIPROCESSOR: 114688\n",
      "\t MAXIMUM_TEXTURE1D_WIDTH: 65536\n",
      "\t MEMORY_CLOCK_RATE: 2505000\n",
      "\t MAX_REGISTERS_PER_MULTIPROCESSOR: 131072\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(drv.Device.count()):\n",
    "    \n",
    "    gpu_device = drv.Device(i)\n",
    "    print 'Device {}: {}'.format( i, gpu_device.name() ) \n",
    "    compute_capability = float( '%d.%d' % gpu_device.compute_capability() )\n",
    "    print '\\t Compute Capability: {}'.format(compute_capability)\n",
    "    print '\\t Total Memory: {} megabytes'.format(gpu_device.total_memory()//(1024**2))\n",
    "    \n",
    "    # The following will give us all remaining device attributes as seen \n",
    "    # in the original deviceQuery.\n",
    "    # We set up a dictionary as such so that we can easily index\n",
    "    # the values using a string descriptor.\n",
    "    \n",
    "    device_attributes_tuples = gpu_device.get_attributes().iteritems() \n",
    "    device_attributes = {}\n",
    "    \n",
    "    for k, v in device_attributes_tuples:\n",
    "        device_attributes[str(k)] = v\n",
    "    \n",
    "    num_mp = device_attributes['MULTIPROCESSOR_COUNT']\n",
    "    \n",
    "    # Cores per multiprocessor is not reported by the GPU!  \n",
    "    # We must use a lookup table based on compute capability.\n",
    "    # See the following:\n",
    "    # http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities\n",
    "    \n",
    "    cuda_cores_per_mp = {3.7:32, 5.0 : 128, 5.1 : 128, 5.2 : 128, 6.0 : 64, 6.1 : 128, 6.2 : 128}[compute_capability]\n",
    "    \n",
    "    print '\\t ({}) Multiprocessors, ({}) CUDA Cores / Multiprocessor: {} CUDA Cores'.format(num_mp, cuda_cores_per_mp, num_mp*cuda_cores_per_mp)\n",
    "    \n",
    "    device_attributes.pop('MULTIPROCESSOR_COUNT')\n",
    "    \n",
    "    for k in device_attributes.keys():\n",
    "        print '\\t {}: {}'.format(k, device_attributes[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python2)",
   "language": "python",
   "name": "conda_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
