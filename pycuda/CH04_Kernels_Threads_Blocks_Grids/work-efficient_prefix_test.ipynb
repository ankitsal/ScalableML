{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "from pycuda import gpuarray\n",
    "from pycuda.compiler import SourceModule\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a work-efficent parallel prefix-sum algorithm.\n",
    "# written by Brian Tuomanen for \"Hands On GPU Programming with Python and CUDA\"\n",
    "\n",
    "# kernel for up-sweep phase\n",
    "up_ker = SourceModule(\"\"\"\n",
    "__global__ void up_ker(double *x, double *x_old, int k )\n",
    "{\n",
    "     int tid =  blockIdx.x*blockDim.x + threadIdx.x;\n",
    "     \n",
    "     int _2k = 1 << k;\n",
    "     int _2k1 = 1 << (k+1);\n",
    "     \n",
    "     int j = tid* _2k1;\n",
    "     \n",
    "     x[j + _2k1 - 1] = x_old[j + _2k -1 ] + x_old[j + _2k1 - 1];\n",
    "\n",
    "}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_gpu = up_ker.get_function(\"up_ker\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of up-sweep phase\n",
    "def up_sweep(x):\n",
    "    # let's typecast to be safe.\n",
    "    x = np.float64(x)\n",
    "    x_gpu = gpuarray.to_gpu(np.float64(x) )\n",
    "    x_old_gpu = x_gpu.copy()\n",
    "    for k in range( int(np.log2(x.size) ) ) : \n",
    "        num_threads = int(np.ceil( x.size / 2**(k+1)))\n",
    "        grid_size = int(np.ceil(num_threads / 32))\n",
    "        \n",
    "        if grid_size > 1:\n",
    "            block_size = 32\n",
    "        else:\n",
    "            block_size = num_threads\n",
    "            \n",
    "        up_gpu(x_gpu, x_old_gpu, np.int32(k)  , block=(block_size,1,1), grid=(grid_size,1,1))\n",
    "        x_old_gpu[:] = x_gpu[:]\n",
    "        \n",
    "    x_out = x_gpu.get()\n",
    "    return(x_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel for down-sweep phase\n",
    "down_ker = SourceModule(\"\"\"\n",
    "__global__ void down_ker(double *y, double *y_old,  int k)\n",
    "{\n",
    "     int tid =  blockIdx.x*blockDim.x + threadIdx.x;\n",
    "     \n",
    "     int _2k = 1 << k;\n",
    "     int _2k1 = 1 << (k+1);\n",
    "     \n",
    "     int j = tid*_2k1;\n",
    "     \n",
    "     y[j + _2k - 1 ] = y_old[j + _2k1 - 1];\n",
    "     y[j + _2k1 - 1] = y_old[j + _2k1 - 1] + y_old[j + _2k - 1];\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "down_gpu = down_ker.get_function(\"down_ker\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of down-sweep phase\n",
    "def down_sweep(y):\n",
    "    y = np.float64(y)\n",
    "    y[-1] = 0\n",
    "    y_gpu = gpuarray.to_gpu(y)\n",
    "    y_old_gpu = y_gpu.copy()\n",
    "    for k in reversed(range(int(np.log2(y.size)))):\n",
    "        num_threads = int(np.ceil( y.size / 2**(k+1)))\n",
    "        grid_size = int(np.ceil(num_threads / 32))\n",
    "        \n",
    "        if grid_size > 1:\n",
    "            block_size = 32\n",
    "        else:\n",
    "            block_size = num_threads\n",
    "            \n",
    "        down_gpu(y_gpu, y_old_gpu, np.int32(k), block=(block_size,1,1), grid=(grid_size,1,1))\n",
    "        y_old_gpu[:] = y_gpu[:]\n",
    "    y_out = y_gpu.get()\n",
    "    return(y_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full implementation of work-efficient parallel prefix sum\n",
    "def efficient_prefix(x):\n",
    "        return(down_sweep(up_sweep(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does our work-efficient prefix work? True\n"
     ]
    }
   ],
   "source": [
    "testvec = np.random.randn(32*1024).astype(np.float64)\n",
    "testvec_gpu = gpuarray.to_gpu(testvec)\n",
    "\n",
    "outvec_gpu = gpuarray.empty_like(testvec_gpu)\n",
    "\n",
    "prefix_sum = np.roll(np.cumsum(testvec), 1)\n",
    "prefix_sum[0] = 0\n",
    "\n",
    "prefix_sum_gpu = efficient_prefix(testvec)\n",
    "\n",
    "print \"Does our work-efficient prefix work? {}\".format(np.allclose(prefix_sum_gpu, prefix_sum))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_python2)",
   "language": "python",
   "name": "conda_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
